CS 179 GPU Computing
Jalen Green
Assignment 1


1.1
-----------
void test1(){
    int *a = 3; // This initializes the pointer value to 3,
                // we do not know what is at this address,
                // or if it is accessible, so this is incorrect
    *a = *a + 2;
    printf("%d",*a);
}

// CORRECTED VERSION
void test1_c(){
	int *a = (int *) malloc(sizeof(int)); // Allocate memory first
	*a = 3;
	*a = *a + 2;
	printf("%d", *a);
    free(a);
}

1.2
---------------
Creates two integer pointers and sets the values to which they point to 2 and 3, respectively.


void test2(){
    int* a,b; // here, b is declared as an int
              // but we want it to be an int pointer
    a = (int*) malloc(sizeof(int));
    b = (int*) malloc(sizeof(int));

    if (!(a && b)){
        printf("Out of memory");
        exit(-1);
    }
    *a = 2;
    *b = 3;
}

// CORRECTED VERSION
void test2_c(){
    int *a, *b; // now b is an int pointer
    a = (int*) malloc(sizeof(int));
    b = (int*) malloc(sizeof(int));

    if (!(a && b)){
        printf("Out of memory");
        exit(-1);
    }
    *a = 2;
    *b = 3;
}


1.3
-----------------
Allocates an array of 1000 integers, and for i = 0,...,999, sets the i-th element to i.


void test3(){
    // must allocate enough memory for int[1000],
    // which is 1000 * sizeof(int), not necessarily 1000.
    int i, *a = (int*) malloc(1000);

    if (!a){
        printf("Out of memory");
        exit(-1);
    }
    for (i = 0; i < 1000; i++)
        *(i+a)=i;
}

// CORRECTED VERSION
void test3_c(){
    // allocate an appropriate size for int[1000]
    int i, *a = (int*) malloc(1000 * sizeof(int));

    if (!a){
        printf("Out of memory");
        exit(-1);
    }
    for (i = 0; i < 1000; i++)
        *(a+i)=i; // Do pointer arithmetic to account for size
                  // of pointer value
    free(a);
}


1.4
---------------
Creates a two-dimensional array of size 3x100, and sets element (1,1) (counting from 0) to 5.


void test4(){
    int **a = (int**) malloc(3*sizeof(int*));
    // the inner pointers are not initialized and
    // memory is not allocated for them
    a[1][1] = 5;
}

// CORRECTED VERSION
void test4_c() {
    int **a = (int**) malloc(3*sizeof(int*));

    // Initialize inner pointers and allocate memory
    for (int i = 0; i < 3; ++i) {
        *(a + i) = (int*) malloc(sizeof(int[100]));
        if (! (*(a + i))) {
            printf("Out of memory");
            exit(-1);
        }
    }

    a[1][1] = 5;

    // Free all allocated memory
    for (int i = 0; i < 3; ++i) {
        free(*(a + i));
    }
    
    free(a);
}

1.5
---------------------

Sets the value pointed to by a to an input, checks if the value pointed to by a is 0, and prints a message if it is.


void test5(){
    int *a = (int*) malloc(sizeof(int));
    scanf("%d",a);
    if (!a) // should be *a == 0, we want the value of the int, not address
        printf("Value is 0\n");
    // Need to free a to prevent memory leak.
}

void test5_c(){
    int *a = (int*) malloc(sizeof(int));
    // Check if memory allocation succeeded
    if (!a){
        printf("Out of memory");
        exit(-1);
    }

    scanf("%d",a);
    if (*a == 0)
        printf("Value is 0\n");

    free(a);
}


Question 2: Parallelization (30pts)
--------------------------------------------------------
--------------------------------------------------------


2.1
---------------------

Given an input signal x[n], suppose we have two output signals y_1[n] and y_2[n], given by the difference equations: 
        y_1[n] = x[n-1] + x[n] + x[n+1]
        y_2[n] = y_2[n-2] + y_2[n-1] + x[n]

Which calculation do you expect will have an easier and faster implementation on the GPU, and why?

Answer:
y_1 will have an easier and faster implementation on the GPU because the
calculation of any element in y_1 only depends on elements in x, which are
already computed and in memory. Thus each element of y_1 can be calculated
in parallel.

Calculating an element of y_2 depends on previous elements in y_2, so earlier
elements must be calculated before later elements in the array. Thus the 
elements of the array must be calculated serially.


2.2
---------------------

In class, we discussed how the exponential moving average (EMA), in comparison to the simple moving average (SMA), is much less suited for parallelization on the GPU. 

Recall that the EMA is given by:
    y[n] = c x[n] + (1-c) y[n-1]

Suppose that c is close to 1, and we only require an approximation to y[n]. How can we get this approximation in a way that is parallelizable? (Explain in words, optionally along with pseudocode or equations.)

Hint: If c is close to 1, then 1-c is close to 0. If you expand the recurrence relation a bit, what happens to the contribution (to y[n]) of the terms y[n-k] as k increases?

Answer:
y[n] = c x[n] + (1-c) y[n-1]
y[n] = c x[n] + (1-c) (c x[n-1] + (1-c) y[n-2])
y[n] = c x[n] + (1-c) (c x[n-1]) + (1-c)^2 y[n-2]
y[n] = c x[n] + (1-c) (c x[n-1]) + (1-c)^2 (c x[n-2] + (1-c) y[n-3])
y[n] = c x[n] + (1-c) (c x[n-1]) + (1-c)^2 (c x[n-2]) + (1-c)^3 y[n-3]
...
y[n] = Sum(i=0 to i=n, (1-c)^(i) c x[n-i])

(1-c) is close to 0, so (1-c)^N diminishes quickly as N is increased.
Choose a suitable N such that (1-c)^N * (any element in x) << (any element in x),
then approximate y[n] as Sum(i=0 to i=N, (1-c)^i c x[n-i]).

For example, choosing N = 2, we can approximate
y[n] approx= c x[n] + (1-c) (c x[n-1])

